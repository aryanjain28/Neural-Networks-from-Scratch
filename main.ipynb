{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.3333332  0.3333332  0.33333364]\n",
      " [0.3333329  0.33333293 0.3333342 ]\n",
      " [0.3333326  0.33333263 0.33333477]\n",
      " [0.33333233 0.3333324  0.33333528]]\n",
      "Avg Loss:  1.0986104\n",
      "Accuracy:  0.34\n"
     ]
    }
   ],
   "source": [
    "# Our Full Code\n",
    "\n",
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "# Dense Layer\n",
    "class Layer_Dense:\n",
    "\n",
    "    # Layer init\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "# ReLU activation function\n",
    "class Activation_ReLU:\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "# Softmax Activation Function\n",
    "class Activation_Softmax:\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        expo_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        norm_values = expo_values / np.sum(expo_values, axis=1, keepdims=True)\n",
    "        self.output = norm_values\n",
    "\n",
    "# Common Loss\n",
    "class Loss:\n",
    "\n",
    "    # output => model's prediction\n",
    "    # y => ground truth\n",
    "    def calculate(self, output, y):\n",
    "        # forward method is of specific loss function eg. Cross Entropy\n",
    "        sample_losses = self.forward(output, y)\n",
    "        \n",
    "        data_loss = np.mean(sample_losses)\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "\n",
    "# Cross Entropy Loss:\n",
    "class Loss_Categorical_Cross_Entropy(Loss):\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # check if y_true is sparse or one-hot-coded\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidence = y_pred_clipped[range(len(y_pred_clipped)), y_true]\n",
    "        else:\n",
    "            correct_confidence = np.sum(y_pred_clipped * y_true, axis=1)\n",
    "\n",
    "        # Losses\n",
    "        neg_log = -np.log(correct_confidence)\n",
    "        return neg_log\n",
    "\n",
    "\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Initialization\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "loss_function = Loss_Categorical_Cross_Entropy()\n",
    "\n",
    "# Forward pass\n",
    "dense1.forward(X)\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "print(activation2.output[:5])\n",
    "\n",
    "loss = loss_function.calculate(activation2.output, y)\n",
    "print(\"Avg Loss: \", loss)\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "# outputs the index from softmax_output\n",
    "predictions = np.argmax(activation2.output, axis=1)\n",
    "\n",
    "if len(y.shape) == 2:\n",
    "    y = np.argmax(y, axis=2)\n",
    "\n",
    "accuracy = np.mean(predictions == y)\n",
    "\n",
    "# True evaluates to 1; False to 0\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter-6 : Introducing Optimization\n",
    "\n",
    "Basically, \"how\" can we adjust the weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How can one optimize the weights and biases to reduce loss?\n",
    "\n",
    "# One option can be randomly changing the weights, checking the loss, and repeating this until lowest loss.\n",
    "# Below code will describe this approach\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nnfs\n",
    "from nnfs.datasets import vertical_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "X, y = vertical_data(samples=100, classes=3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=\"brg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Loss:  1.1016203\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  1\n",
      "Loss:  1.1002508\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  2\n",
      "Loss:  1.0992025\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  3\n",
      "Loss:  1.0986239\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  4\n",
      "Loss:  1.0989311\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  5\n",
      "Loss:  1.0999966\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  6\n",
      "Loss:  1.0996981\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  7\n",
      "Loss:  1.0990195\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  8\n",
      "Loss:  1.1009971\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  9\n",
      "Loss:  1.0989053\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  10\n",
      "Loss:  1.0984299\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  11\n",
      "Loss:  1.0985516\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  12\n",
      "Loss:  1.0987039\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  13\n",
      "Loss:  1.0988864\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  14\n",
      "Loss:  1.1004544\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  15\n",
      "Loss:  1.098729\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  16\n",
      "Loss:  1.098967\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  17\n",
      "Loss:  1.1000205\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  18\n",
      "Loss:  1.1025857\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  19\n",
      "Loss:  1.0986536\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  20\n",
      "Loss:  1.0993116\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  21\n",
      "Loss:  1.099614\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  22\n",
      "Loss:  1.0976521\n",
      "Accuracy:  0.36333333333333334\n",
      "Iteration:  23\n",
      "Loss:  1.0993097\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  24\n",
      "Loss:  1.0991212\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  25\n",
      "Loss:  1.0996602\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  26\n",
      "Loss:  1.0989219\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  27\n",
      "Loss:  1.0990744\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  28\n",
      "Loss:  1.0995101\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  29\n",
      "Loss:  1.0998918\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  30\n",
      "Loss:  1.0993197\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  31\n",
      "Loss:  1.0993489\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  32\n",
      "Loss:  1.098777\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  33\n",
      "Loss:  1.099666\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  34\n",
      "Loss:  1.1017406\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  35\n",
      "Loss:  1.1001064\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  36\n",
      "Loss:  1.0996405\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  37\n",
      "Loss:  1.0992457\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  38\n",
      "Loss:  1.0990161\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  39\n",
      "Loss:  1.0994983\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  40\n",
      "Loss:  1.0986261\n",
      "Accuracy:  0.06\n",
      "Iteration:  41\n",
      "Loss:  1.1001846\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  42\n",
      "Loss:  1.1006479\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  43\n",
      "Loss:  1.0986868\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  44\n",
      "Loss:  1.0987897\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  45\n",
      "Loss:  1.1003318\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  46\n",
      "Loss:  1.0991119\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  47\n",
      "Loss:  1.1006119\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  48\n",
      "Loss:  1.0987232\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  49\n",
      "Loss:  1.0992332\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  50\n",
      "Loss:  1.098878\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  51\n",
      "Loss:  1.0987537\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  52\n",
      "Loss:  1.1009979\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  53\n",
      "Loss:  1.0985993\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  54\n",
      "Loss:  1.0992883\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  55\n",
      "Loss:  1.098837\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  56\n",
      "Loss:  1.09929\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  57\n",
      "Loss:  1.0991052\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  58\n",
      "Loss:  1.1010091\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  59\n",
      "Loss:  1.0991546\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  60\n",
      "Loss:  1.0994875\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  61\n",
      "Loss:  1.0987127\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  62\n",
      "Loss:  1.0990094\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  63\n",
      "Loss:  1.0995411\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  64\n",
      "Loss:  1.0990065\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  65\n",
      "Loss:  1.0985767\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  66\n",
      "Loss:  1.0992461\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  67\n",
      "Loss:  1.0997486\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  68\n",
      "Loss:  1.0995643\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  69\n",
      "Loss:  1.0991324\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  70\n",
      "Loss:  1.0985982\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  71\n",
      "Loss:  1.0992688\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  72\n",
      "Loss:  1.0980906\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  73\n",
      "Loss:  1.0980681\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  74\n",
      "Loss:  1.0985404\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  75\n",
      "Loss:  1.0991355\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  76\n",
      "Loss:  1.0995257\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  77\n",
      "Loss:  1.0990975\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  78\n",
      "Loss:  1.0985112\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  79\n",
      "Loss:  1.0983949\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  80\n",
      "Loss:  1.0994335\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  81\n",
      "Loss:  1.099778\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  82\n",
      "Loss:  1.0996008\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  83\n",
      "Loss:  1.0998443\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  84\n",
      "Loss:  1.0993267\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  85\n",
      "Loss:  1.101896\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  86\n",
      "Loss:  1.0997715\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  87\n",
      "Loss:  1.0990056\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  88\n",
      "Loss:  1.1042157\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  89\n",
      "Loss:  1.0997272\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  90\n",
      "Loss:  1.1005597\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  91\n",
      "Loss:  1.0987396\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  92\n",
      "Loss:  1.0997512\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  93\n",
      "Loss:  1.0991734\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  94\n",
      "Loss:  1.1011745\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  95\n",
      "Loss:  1.1002134\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  96\n",
      "Loss:  1.0997305\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  97\n",
      "Loss:  1.0994338\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  98\n",
      "Loss:  1.0985408\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  99\n",
      "Loss:  1.0994376\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  100\n",
      "Loss:  1.1006076\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  101\n",
      "Loss:  1.0987376\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  102\n",
      "Loss:  1.1006461\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  103\n",
      "Loss:  1.0985801\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  104\n",
      "Loss:  1.0992233\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  105\n",
      "Loss:  1.0981708\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  106\n",
      "Loss:  1.0998139\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  107\n",
      "Loss:  1.0992552\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  108\n",
      "Loss:  1.0995564\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  109\n",
      "Loss:  1.0993232\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  110\n",
      "Loss:  1.1046091\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  111\n",
      "Loss:  1.0987756\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  112\n",
      "Loss:  1.1001095\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  113\n",
      "Loss:  1.1000475\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  114\n",
      "Loss:  1.1011924\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  115\n",
      "Loss:  1.0976573\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  116\n",
      "Loss:  1.0981954\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  117\n",
      "Loss:  1.1001294\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  118\n",
      "Loss:  1.0996095\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  119\n",
      "Loss:  1.0995568\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  120\n",
      "Loss:  1.1011263\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  121\n",
      "Loss:  1.0987333\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  122\n",
      "Loss:  1.0984793\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  123\n",
      "Loss:  1.0987909\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  124\n",
      "Loss:  1.0992898\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  125\n",
      "Loss:  1.0994793\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  126\n",
      "Loss:  1.0993581\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  127\n",
      "Loss:  1.0984946\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  128\n",
      "Loss:  1.101081\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  129\n",
      "Loss:  1.0989432\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  130\n",
      "Loss:  1.0998837\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  131\n",
      "Loss:  1.098785\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  132\n",
      "Loss:  1.0986526\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  133\n",
      "Loss:  1.1001672\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  134\n",
      "Loss:  1.0977105\n",
      "Accuracy:  0.36333333333333334\n",
      "Iteration:  135\n",
      "Loss:  1.0984986\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  136\n",
      "Loss:  1.0987813\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  137\n",
      "Loss:  1.099388\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  138\n",
      "Loss:  1.0986713\n",
      "Accuracy:  0.3433333333333333\n",
      "Iteration:  139\n",
      "Loss:  1.1002666\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  140\n",
      "Loss:  1.1013471\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  141\n",
      "Loss:  1.0997009\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  142\n",
      "Loss:  1.1005241\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  143\n",
      "Loss:  1.0997274\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  144\n",
      "Loss:  1.0995264\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  145\n",
      "Loss:  1.0986837\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  146\n",
      "Loss:  1.1002588\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  147\n",
      "Loss:  1.0989656\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  148\n",
      "Loss:  1.1011685\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  149\n",
      "Loss:  1.099137\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  150\n",
      "Loss:  1.0974255\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  151\n",
      "Loss:  1.0985249\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  152\n",
      "Loss:  1.0992281\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  153\n",
      "Loss:  1.1000257\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  154\n",
      "Loss:  1.1015688\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  155\n",
      "Loss:  1.0995357\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  156\n",
      "Loss:  1.0985295\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  157\n",
      "Loss:  1.0990592\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  158\n",
      "Loss:  1.0985652\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  159\n",
      "Loss:  1.098831\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  160\n",
      "Loss:  1.0998247\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  161\n",
      "Loss:  1.0988654\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  162\n",
      "Loss:  1.0990137\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  163\n",
      "Loss:  1.098742\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  164\n",
      "Loss:  1.0983118\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  165\n",
      "Loss:  1.1006675\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  166\n",
      "Loss:  1.0988294\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  167\n",
      "Loss:  1.0982906\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  168\n",
      "Loss:  1.0999651\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  169\n",
      "Loss:  1.0992802\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  170\n",
      "Loss:  1.0989181\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  171\n",
      "Loss:  1.0999577\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  172\n",
      "Loss:  1.0989469\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  173\n",
      "Loss:  1.0987356\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  174\n",
      "Loss:  1.0995209\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  175\n",
      "Loss:  1.1057028\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  176\n",
      "Loss:  1.0992497\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  177\n",
      "Loss:  1.0991178\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  178\n",
      "Loss:  1.0993292\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  179\n",
      "Loss:  1.0985554\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  180\n",
      "Loss:  1.0991813\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  181\n",
      "Loss:  1.0999997\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  182\n",
      "Loss:  1.1015815\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  183\n",
      "Loss:  1.0991514\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  184\n",
      "Loss:  1.0994914\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  185\n",
      "Loss:  1.1005232\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  186\n",
      "Loss:  1.1014984\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  187\n",
      "Loss:  1.0987606\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  188\n",
      "Loss:  1.1000534\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  189\n",
      "Loss:  1.1004174\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  190\n",
      "Loss:  1.0987372\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  191\n",
      "Loss:  1.0996361\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  192\n",
      "Loss:  1.1006224\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  193\n",
      "Loss:  1.0992106\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  194\n",
      "Loss:  1.1000175\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  195\n",
      "Loss:  1.1007032\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  196\n",
      "Loss:  1.0988911\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  197\n",
      "Loss:  1.0994527\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  198\n",
      "Loss:  1.0996313\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  199\n",
      "Loss:  1.098466\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  200\n",
      "Loss:  1.0984895\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  201\n",
      "Loss:  1.0999565\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  202\n",
      "Loss:  1.1002258\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  203\n",
      "Loss:  1.1008894\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  204\n",
      "Loss:  1.0983287\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  205\n",
      "Loss:  1.0990068\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  206\n",
      "Loss:  1.099128\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  207\n",
      "Loss:  1.1015365\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  208\n",
      "Loss:  1.098785\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  209\n",
      "Loss:  1.0982214\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  210\n",
      "Loss:  1.0989803\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  211\n",
      "Loss:  1.1001464\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  212\n",
      "Loss:  1.1000946\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  213\n",
      "Loss:  1.098681\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  214\n",
      "Loss:  1.098915\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  215\n",
      "Loss:  1.1001475\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  216\n",
      "Loss:  1.0994158\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  217\n",
      "Loss:  1.0993149\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  218\n",
      "Loss:  1.1015385\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  219\n",
      "Loss:  1.0994487\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  220\n",
      "Loss:  1.0989392\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  221\n",
      "Loss:  1.0996633\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  222\n",
      "Loss:  1.098964\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  223\n",
      "Loss:  1.0998302\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  224\n",
      "Loss:  1.0986037\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  225\n",
      "Loss:  1.0992802\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  226\n",
      "Loss:  1.0981793\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  227\n",
      "Loss:  1.1000729\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  228\n",
      "Loss:  1.0987848\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  229\n",
      "Loss:  1.099641\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  230\n",
      "Loss:  1.0985264\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  231\n",
      "Loss:  1.1004503\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  232\n",
      "Loss:  1.0985584\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  233\n",
      "Loss:  1.0991415\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  234\n",
      "Loss:  1.0996819\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  235\n",
      "Loss:  1.1008395\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  236\n",
      "Loss:  1.0995178\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  237\n",
      "Loss:  1.0992907\n",
      "Accuracy:  0.32666666666666666\n",
      "Iteration:  238\n",
      "Loss:  1.0998517\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  239\n",
      "Loss:  1.1002791\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  240\n",
      "Loss:  1.0983741\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  241\n",
      "Loss:  1.1013438\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  242\n",
      "Loss:  1.0986605\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  243\n",
      "Loss:  1.0991838\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  244\n",
      "Loss:  1.0988399\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  245\n",
      "Loss:  1.1030306\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  246\n",
      "Loss:  1.0994418\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  247\n",
      "Loss:  1.1005087\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  248\n",
      "Loss:  1.0990499\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  249\n",
      "Loss:  1.0992959\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  250\n",
      "Loss:  1.099488\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  251\n",
      "Loss:  1.0994793\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  252\n",
      "Loss:  1.0992798\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  253\n",
      "Loss:  1.1024433\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  254\n",
      "Loss:  1.1013281\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  255\n",
      "Loss:  1.1001123\n",
      "Accuracy:  0.05\n",
      "Iteration:  256\n",
      "Loss:  1.0981398\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  257\n",
      "Loss:  1.0987449\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  258\n",
      "Loss:  1.1005535\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  259\n",
      "Loss:  1.0990446\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  260\n",
      "Loss:  1.0990607\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  261\n",
      "Loss:  1.099591\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  262\n",
      "Loss:  1.0982052\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  263\n",
      "Loss:  1.0983193\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  264\n",
      "Loss:  1.0986304\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  265\n",
      "Loss:  1.0981323\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  266\n",
      "Loss:  1.0987619\n",
      "Accuracy:  0.21\n",
      "Iteration:  267\n",
      "Loss:  1.0991082\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  268\n",
      "Loss:  1.098647\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  269\n",
      "Loss:  1.0999221\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  270\n",
      "Loss:  1.0994703\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  271\n",
      "Loss:  1.0990826\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  272\n",
      "Loss:  1.0992948\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  273\n",
      "Loss:  1.0980312\n",
      "Accuracy:  0.37333333333333335\n",
      "Iteration:  274\n",
      "Loss:  1.0989457\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  275\n",
      "Loss:  1.0994575\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  276\n",
      "Loss:  1.0987514\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  277\n",
      "Loss:  1.0999343\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  278\n",
      "Loss:  1.0991061\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  279\n",
      "Loss:  1.099018\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  280\n",
      "Loss:  1.1002936\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  281\n",
      "Loss:  1.100123\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  282\n",
      "Loss:  1.0989388\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  283\n",
      "Loss:  1.0998557\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  284\n",
      "Loss:  1.0990272\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  285\n",
      "Loss:  1.0978029\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  286\n",
      "Loss:  1.1002113\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  287\n",
      "Loss:  1.0990483\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  288\n",
      "Loss:  1.1022172\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  289\n",
      "Loss:  1.1003827\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  290\n",
      "Loss:  1.1003317\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  291\n",
      "Loss:  1.0986423\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  292\n",
      "Loss:  1.0990871\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  293\n",
      "Loss:  1.101323\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  294\n",
      "Loss:  1.1005565\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  295\n",
      "Loss:  1.1004328\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  296\n",
      "Loss:  1.099964\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  297\n",
      "Loss:  1.099134\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  298\n",
      "Loss:  1.0988503\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  299\n",
      "Loss:  1.1019242\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  300\n",
      "Loss:  1.1000806\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  301\n",
      "Loss:  1.0986859\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  302\n",
      "Loss:  1.1015944\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  303\n",
      "Loss:  1.0985976\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  304\n",
      "Loss:  1.098705\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  305\n",
      "Loss:  1.0987442\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  306\n",
      "Loss:  1.0987813\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  307\n",
      "Loss:  1.098782\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  308\n",
      "Loss:  1.0989958\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  309\n",
      "Loss:  1.0986259\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  310\n",
      "Loss:  1.0989903\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  311\n",
      "Loss:  1.1031939\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  312\n",
      "Loss:  1.0981733\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  313\n",
      "Loss:  1.0985819\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  314\n",
      "Loss:  1.0990958\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  315\n",
      "Loss:  1.0996376\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  316\n",
      "Loss:  1.0991799\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  317\n",
      "Loss:  1.100178\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  318\n",
      "Loss:  1.0991695\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  319\n",
      "Loss:  1.0996511\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  320\n",
      "Loss:  1.0990362\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  321\n",
      "Loss:  1.0994179\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  322\n",
      "Loss:  1.098705\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  323\n",
      "Loss:  1.098991\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  324\n",
      "Loss:  1.0996068\n",
      "Accuracy:  0.2833333333333333\n",
      "Iteration:  325\n",
      "Loss:  1.0985937\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  326\n",
      "Loss:  1.0989\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  327\n",
      "Loss:  1.0991715\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  328\n",
      "Loss:  1.1012005\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  329\n",
      "Loss:  1.0995063\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  330\n",
      "Loss:  1.1005865\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  331\n",
      "Loss:  1.0989219\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  332\n",
      "Loss:  1.0987566\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  333\n",
      "Loss:  1.0990734\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  334\n",
      "Loss:  1.0991802\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  335\n",
      "Loss:  1.0993266\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  336\n",
      "Loss:  1.1003121\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  337\n",
      "Loss:  1.0988566\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  338\n",
      "Loss:  1.1010013\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  339\n",
      "Loss:  1.0988683\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  340\n",
      "Loss:  1.1004164\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  341\n",
      "Loss:  1.0994757\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  342\n",
      "Loss:  1.0990268\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  343\n",
      "Loss:  1.0986891\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  344\n",
      "Loss:  1.099903\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  345\n",
      "Loss:  1.0992179\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  346\n",
      "Loss:  1.10028\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  347\n",
      "Loss:  1.0993094\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  348\n",
      "Loss:  1.0992668\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  349\n",
      "Loss:  1.0987309\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  350\n",
      "Loss:  1.0989078\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  351\n",
      "Loss:  1.1018012\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  352\n",
      "Loss:  1.0981232\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  353\n",
      "Loss:  1.0987773\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  354\n",
      "Loss:  1.0994098\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  355\n",
      "Loss:  1.1000065\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  356\n",
      "Loss:  1.0999082\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  357\n",
      "Loss:  1.099187\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  358\n",
      "Loss:  1.0986837\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  359\n",
      "Loss:  1.1001418\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  360\n",
      "Loss:  1.0994837\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  361\n",
      "Loss:  1.0993171\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  362\n",
      "Loss:  1.0983812\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  363\n",
      "Loss:  1.0987685\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  364\n",
      "Loss:  1.1003934\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  365\n",
      "Loss:  1.101694\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  366\n",
      "Loss:  1.0988171\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  367\n",
      "Loss:  1.098792\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  368\n",
      "Loss:  1.099078\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  369\n",
      "Loss:  1.0992615\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  370\n",
      "Loss:  1.1004537\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  371\n",
      "Loss:  1.0981442\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  372\n",
      "Loss:  1.1001402\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  373\n",
      "Loss:  1.101371\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  374\n",
      "Loss:  1.1006454\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  375\n",
      "Loss:  1.0991648\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  376\n",
      "Loss:  1.0988053\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  377\n",
      "Loss:  1.0980489\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  378\n",
      "Loss:  1.099489\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  379\n",
      "Loss:  1.1048111\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  380\n",
      "Loss:  1.0987757\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  381\n",
      "Loss:  1.0990157\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  382\n",
      "Loss:  1.0989496\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  383\n",
      "Loss:  1.0984156\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  384\n",
      "Loss:  1.1001819\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  385\n",
      "Loss:  1.1008693\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  386\n",
      "Loss:  1.0993068\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  387\n",
      "Loss:  1.09898\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  388\n",
      "Loss:  1.0988156\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  389\n",
      "Loss:  1.1015323\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  390\n",
      "Loss:  1.1006684\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  391\n",
      "Loss:  1.0977585\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  392\n",
      "Loss:  1.099243\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  393\n",
      "Loss:  1.100261\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  394\n",
      "Loss:  1.0998757\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  395\n",
      "Loss:  1.100956\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  396\n",
      "Loss:  1.0987594\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  397\n",
      "Loss:  1.0991474\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  398\n",
      "Loss:  1.0995333\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  399\n",
      "Loss:  1.1003133\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  400\n",
      "Loss:  1.0989484\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  401\n",
      "Loss:  1.0999006\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  402\n",
      "Loss:  1.099287\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  403\n",
      "Loss:  1.0984391\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  404\n",
      "Loss:  1.0987471\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  405\n",
      "Loss:  1.0979236\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  406\n",
      "Loss:  1.0988818\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  407\n",
      "Loss:  1.0995176\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  408\n",
      "Loss:  1.0982314\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  409\n",
      "Loss:  1.0986849\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  410\n",
      "Loss:  1.0993989\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  411\n",
      "Loss:  1.0978105\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  412\n",
      "Loss:  1.0988375\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  413\n",
      "Loss:  1.0998623\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  414\n",
      "Loss:  1.0990695\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  415\n",
      "Loss:  1.0995431\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  416\n",
      "Loss:  1.0991479\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  417\n",
      "Loss:  1.099234\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  418\n",
      "Loss:  1.10046\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  419\n",
      "Loss:  1.0984857\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  420\n",
      "Loss:  1.098951\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  421\n",
      "Loss:  1.09942\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  422\n",
      "Loss:  1.1006927\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  423\n",
      "Loss:  1.0989275\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  424\n",
      "Loss:  1.099257\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  425\n",
      "Loss:  1.0982103\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  426\n",
      "Loss:  1.0993968\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  427\n",
      "Loss:  1.0996058\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  428\n",
      "Loss:  1.0989093\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  429\n",
      "Loss:  1.0977563\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  430\n",
      "Loss:  1.0980409\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  431\n",
      "Loss:  1.0987889\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  432\n",
      "Loss:  1.10005\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  433\n",
      "Loss:  1.1018034\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  434\n",
      "Loss:  1.0988605\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  435\n",
      "Loss:  1.0998394\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  436\n",
      "Loss:  1.0993406\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  437\n",
      "Loss:  1.0989652\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  438\n",
      "Loss:  1.0999271\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  439\n",
      "Loss:  1.0992088\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  440\n",
      "Loss:  1.0985923\n",
      "Accuracy:  0.38\n",
      "Iteration:  441\n",
      "Loss:  1.1001865\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  442\n",
      "Loss:  1.0997599\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  443\n",
      "Loss:  1.099377\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  444\n",
      "Loss:  1.0977231\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  445\n",
      "Loss:  1.0989679\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  446\n",
      "Loss:  1.0992588\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  447\n",
      "Loss:  1.1018885\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  448\n",
      "Loss:  1.0992749\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  449\n",
      "Loss:  1.0992466\n",
      "Accuracy:  0.33\n",
      "Iteration:  450\n",
      "Loss:  1.1000832\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  451\n",
      "Loss:  1.0987296\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  452\n",
      "Loss:  1.1000638\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  453\n",
      "Loss:  1.1002393\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  454\n",
      "Loss:  1.0997602\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  455\n",
      "Loss:  1.0988101\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  456\n",
      "Loss:  1.0987449\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  457\n",
      "Loss:  1.0989611\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  458\n",
      "Loss:  1.0986679\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  459\n",
      "Loss:  1.0986562\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  460\n",
      "Loss:  1.1000164\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  461\n",
      "Loss:  1.1006435\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  462\n",
      "Loss:  1.1011482\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  463\n",
      "Loss:  1.0977372\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  464\n",
      "Loss:  1.0985762\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  465\n",
      "Loss:  1.0983486\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  466\n",
      "Loss:  1.0982875\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  467\n",
      "Loss:  1.098922\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  468\n",
      "Loss:  1.0993427\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  469\n",
      "Loss:  1.100841\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  470\n",
      "Loss:  1.0991547\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  471\n",
      "Loss:  1.1015003\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  472\n",
      "Loss:  1.0989634\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  473\n",
      "Loss:  1.0992529\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  474\n",
      "Loss:  1.0993716\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  475\n",
      "Loss:  1.0992014\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  476\n",
      "Loss:  1.0983876\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  477\n",
      "Loss:  1.098894\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  478\n",
      "Loss:  1.0995147\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  479\n",
      "Loss:  1.098796\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  480\n",
      "Loss:  1.0998962\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  481\n",
      "Loss:  1.0998166\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  482\n",
      "Loss:  1.0985132\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  483\n",
      "Loss:  1.0996096\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  484\n",
      "Loss:  1.0989575\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  485\n",
      "Loss:  1.0993456\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  486\n",
      "Loss:  1.0981927\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  487\n",
      "Loss:  1.0986139\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  488\n",
      "Loss:  1.0993913\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  489\n",
      "Loss:  1.10013\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  490\n",
      "Loss:  1.0993793\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  491\n",
      "Loss:  1.0988903\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  492\n",
      "Loss:  1.0988413\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  493\n",
      "Loss:  1.0987297\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  494\n",
      "Loss:  1.1020186\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  495\n",
      "Loss:  1.0991127\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  496\n",
      "Loss:  1.0995793\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  497\n",
      "Loss:  1.0996807\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  498\n",
      "Loss:  1.1005955\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  499\n",
      "Loss:  1.0987127\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  500\n",
      "Loss:  1.0986238\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  501\n",
      "Loss:  1.100136\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  502\n",
      "Loss:  1.0987324\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  503\n",
      "Loss:  1.098647\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  504\n",
      "Loss:  1.0997953\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  505\n",
      "Loss:  1.100953\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  506\n",
      "Loss:  1.0990217\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  507\n",
      "Loss:  1.0989574\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  508\n",
      "Loss:  1.0988399\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  509\n",
      "Loss:  1.1004262\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  510\n",
      "Loss:  1.0984367\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  511\n",
      "Loss:  1.0996025\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  512\n",
      "Loss:  1.0993274\n",
      "Accuracy:  0.32666666666666666\n",
      "Iteration:  513\n",
      "Loss:  1.0984422\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  514\n",
      "Loss:  1.0993266\n",
      "Accuracy:  0.17\n",
      "Iteration:  515\n",
      "Loss:  1.1001506\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  516\n",
      "Loss:  1.0996716\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  517\n",
      "Loss:  1.1000104\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  518\n",
      "Loss:  1.1053984\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  519\n",
      "Loss:  1.0986818\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  520\n",
      "Loss:  1.0986576\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  521\n",
      "Loss:  1.1019249\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  522\n",
      "Loss:  1.1002584\n",
      "Accuracy:  0.19\n",
      "Iteration:  523\n",
      "Loss:  1.1010774\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  524\n",
      "Loss:  1.0986965\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  525\n",
      "Loss:  1.0996963\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  526\n",
      "Loss:  1.0986441\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  527\n",
      "Loss:  1.1024985\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  528\n",
      "Loss:  1.1000093\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  529\n",
      "Loss:  1.0991113\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  530\n",
      "Loss:  1.100265\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  531\n",
      "Loss:  1.100097\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  532\n",
      "Loss:  1.097457\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  533\n",
      "Loss:  1.0996773\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  534\n",
      "Loss:  1.0988364\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  535\n",
      "Loss:  1.0987518\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  536\n",
      "Loss:  1.0999284\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  537\n",
      "Loss:  1.1001893\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  538\n",
      "Loss:  1.0975456\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  539\n",
      "Loss:  1.0994197\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  540\n",
      "Loss:  1.0991143\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  541\n",
      "Loss:  1.0988536\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  542\n",
      "Loss:  1.0984792\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  543\n",
      "Loss:  1.0995941\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  544\n",
      "Loss:  1.0987674\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  545\n",
      "Loss:  1.0986435\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  546\n",
      "Loss:  1.0994\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  547\n",
      "Loss:  1.0991992\n",
      "Accuracy:  0.32666666666666666\n",
      "Iteration:  548\n",
      "Loss:  1.0994623\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  549\n",
      "Loss:  1.0995017\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  550\n",
      "Loss:  1.0986326\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  551\n",
      "Loss:  1.0986311\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  552\n",
      "Loss:  1.0984343\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  553\n",
      "Loss:  1.0992795\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  554\n",
      "Loss:  1.1006744\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  555\n",
      "Loss:  1.1023436\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  556\n",
      "Loss:  1.1001662\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  557\n",
      "Loss:  1.0988634\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  558\n",
      "Loss:  1.0995188\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  559\n",
      "Loss:  1.1013516\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  560\n",
      "Loss:  1.0986387\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  561\n",
      "Loss:  1.0995774\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  562\n",
      "Loss:  1.0989249\n",
      "Accuracy:  0.33666666666666667\n",
      "Iteration:  563\n",
      "Loss:  1.1011701\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  564\n",
      "Loss:  1.0988554\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  565\n",
      "Loss:  1.0995225\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  566\n",
      "Loss:  1.10017\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  567\n",
      "Loss:  1.0990573\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  568\n",
      "Loss:  1.1005934\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  569\n",
      "Loss:  1.0985844\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  570\n",
      "Loss:  1.0987837\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  571\n",
      "Loss:  1.0989714\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  572\n",
      "Loss:  1.0991367\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  573\n",
      "Loss:  1.1001424\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  574\n",
      "Loss:  1.0993232\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  575\n",
      "Loss:  1.1000565\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  576\n",
      "Loss:  1.0995109\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  577\n",
      "Loss:  1.0989996\n",
      "Accuracy:  0.32666666666666666\n",
      "Iteration:  578\n",
      "Loss:  1.0989566\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  579\n",
      "Loss:  1.098622\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  580\n",
      "Loss:  1.0990373\n",
      "Accuracy:  0.32666666666666666\n",
      "Iteration:  581\n",
      "Loss:  1.0989391\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  582\n",
      "Loss:  1.0997325\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  583\n",
      "Loss:  1.0991582\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  584\n",
      "Loss:  1.0990505\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  585\n",
      "Loss:  1.0996895\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  586\n",
      "Loss:  1.0991001\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  587\n",
      "Loss:  1.0992192\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  588\n",
      "Loss:  1.098835\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  589\n",
      "Loss:  1.0992228\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  590\n",
      "Loss:  1.1012721\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  591\n",
      "Loss:  1.0990002\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  592\n",
      "Loss:  1.0988622\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  593\n",
      "Loss:  1.1003072\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  594\n",
      "Loss:  1.0987629\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  595\n",
      "Loss:  1.09996\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  596\n",
      "Loss:  1.0988315\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  597\n",
      "Loss:  1.0995866\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  598\n",
      "Loss:  1.098896\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  599\n",
      "Loss:  1.0993365\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  600\n",
      "Loss:  1.0986526\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  601\n",
      "Loss:  1.0984765\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  602\n",
      "Loss:  1.097992\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  603\n",
      "Loss:  1.1003109\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  604\n",
      "Loss:  1.0981352\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  605\n",
      "Loss:  1.1007103\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  606\n",
      "Loss:  1.0989308\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  607\n",
      "Loss:  1.0991415\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  608\n",
      "Loss:  1.0991843\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  609\n",
      "Loss:  1.1002355\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  610\n",
      "Loss:  1.0974811\n",
      "Accuracy:  0.5166666666666667\n",
      "Iteration:  611\n",
      "Loss:  1.0997053\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  612\n",
      "Loss:  1.0997101\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  613\n",
      "Loss:  1.1000067\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  614\n",
      "Loss:  1.0987182\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  615\n",
      "Loss:  1.1006202\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  616\n",
      "Loss:  1.0989994\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  617\n",
      "Loss:  1.1001819\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  618\n",
      "Loss:  1.0999769\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  619\n",
      "Loss:  1.0997988\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  620\n",
      "Loss:  1.0986408\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  621\n",
      "Loss:  1.0992028\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  622\n",
      "Loss:  1.1000339\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  623\n",
      "Loss:  1.0991182\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  624\n",
      "Loss:  1.1000726\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  625\n",
      "Loss:  1.09937\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  626\n",
      "Loss:  1.0995667\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  627\n",
      "Loss:  1.0995067\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  628\n",
      "Loss:  1.1013143\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  629\n",
      "Loss:  1.09943\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  630\n",
      "Loss:  1.1008373\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  631\n",
      "Loss:  1.0987283\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  632\n",
      "Loss:  1.0990847\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  633\n",
      "Loss:  1.0987426\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  634\n",
      "Loss:  1.0988686\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  635\n",
      "Loss:  1.0993108\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  636\n",
      "Loss:  1.0989443\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  637\n",
      "Loss:  1.0998524\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  638\n",
      "Loss:  1.1004403\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  639\n",
      "Loss:  1.0992385\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  640\n",
      "Loss:  1.0996822\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  641\n",
      "Loss:  1.100719\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  642\n",
      "Loss:  1.0992438\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  643\n",
      "Loss:  1.100119\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  644\n",
      "Loss:  1.0999073\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  645\n",
      "Loss:  1.099648\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  646\n",
      "Loss:  1.099879\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  647\n",
      "Loss:  1.0985105\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  648\n",
      "Loss:  1.098813\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  649\n",
      "Loss:  1.0987157\n",
      "Accuracy:  0.6666666666666666\n",
      "Iteration:  650\n",
      "Loss:  1.0998969\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  651\n",
      "Loss:  1.0985835\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  652\n",
      "Loss:  1.0993907\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  653\n",
      "Loss:  1.1007379\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  654\n",
      "Loss:  1.1021901\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  655\n",
      "Loss:  1.0983405\n",
      "Accuracy:  0.33\n",
      "Iteration:  656\n",
      "Loss:  1.1009308\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  657\n",
      "Loss:  1.0992599\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  658\n",
      "Loss:  1.0982012\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  659\n",
      "Loss:  1.0998782\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  660\n",
      "Loss:  1.0984408\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  661\n",
      "Loss:  1.0988554\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  662\n",
      "Loss:  1.0986199\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  663\n",
      "Loss:  1.0985053\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  664\n",
      "Loss:  1.099246\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  665\n",
      "Loss:  1.100013\n",
      "Accuracy:  0.21666666666666667\n",
      "Iteration:  666\n",
      "Loss:  1.099538\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  667\n",
      "Loss:  1.0992123\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  668\n",
      "Loss:  1.0983964\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  669\n",
      "Loss:  1.099138\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  670\n",
      "Loss:  1.0987142\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  671\n",
      "Loss:  1.1013863\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  672\n",
      "Loss:  1.0988684\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  673\n",
      "Loss:  1.0990086\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  674\n",
      "Loss:  1.0984699\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  675\n",
      "Loss:  1.0986286\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  676\n",
      "Loss:  1.1011189\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  677\n",
      "Loss:  1.100756\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  678\n",
      "Loss:  1.0984493\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  679\n",
      "Loss:  1.0987877\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  680\n",
      "Loss:  1.0993422\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  681\n",
      "Loss:  1.0987529\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  682\n",
      "Loss:  1.0999696\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  683\n",
      "Loss:  1.099296\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  684\n",
      "Loss:  1.0989709\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  685\n",
      "Loss:  1.0992169\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  686\n",
      "Loss:  1.0986829\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  687\n",
      "Loss:  1.1013397\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  688\n",
      "Loss:  1.0988271\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  689\n",
      "Loss:  1.0998613\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  690\n",
      "Loss:  1.0983953\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  691\n",
      "Loss:  1.0999371\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  692\n",
      "Loss:  1.0997958\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  693\n",
      "Loss:  1.099399\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  694\n",
      "Loss:  1.0993038\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  695\n",
      "Loss:  1.099482\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  696\n",
      "Loss:  1.1003817\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  697\n",
      "Loss:  1.0993302\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  698\n",
      "Loss:  1.0991181\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  699\n",
      "Loss:  1.0989374\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  700\n",
      "Loss:  1.0984436\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  701\n",
      "Loss:  1.0992132\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  702\n",
      "Loss:  1.0980881\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  703\n",
      "Loss:  1.0992421\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  704\n",
      "Loss:  1.0996529\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  705\n",
      "Loss:  1.09898\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  706\n",
      "Loss:  1.0986304\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  707\n",
      "Loss:  1.0985852\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  708\n",
      "Loss:  1.0986875\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  709\n",
      "Loss:  1.0997599\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  710\n",
      "Loss:  1.0992405\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  711\n",
      "Loss:  1.0989481\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  712\n",
      "Loss:  1.0995688\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  713\n",
      "Loss:  1.0993046\n",
      "Accuracy:  0.31666666666666665\n",
      "Iteration:  714\n",
      "Loss:  1.1016523\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  715\n",
      "Loss:  1.0991205\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  716\n",
      "Loss:  1.0990261\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  717\n",
      "Loss:  1.1015633\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  718\n",
      "Loss:  1.1011342\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  719\n",
      "Loss:  1.0984756\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  720\n",
      "Loss:  1.0996096\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  721\n",
      "Loss:  1.0983348\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  722\n",
      "Loss:  1.0994837\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  723\n",
      "Loss:  1.099918\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  724\n",
      "Loss:  1.0984184\n",
      "Accuracy:  0.35\n",
      "Iteration:  725\n",
      "Loss:  1.0995458\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  726\n",
      "Loss:  1.0987386\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  727\n",
      "Loss:  1.1015438\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  728\n",
      "Loss:  1.0997013\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  729\n",
      "Loss:  1.103078\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  730\n",
      "Loss:  1.0991634\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  731\n",
      "Loss:  1.1002539\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  732\n",
      "Loss:  1.0988967\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  733\n",
      "Loss:  1.100477\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  734\n",
      "Loss:  1.1001366\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  735\n",
      "Loss:  1.1012659\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  736\n",
      "Loss:  1.098499\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  737\n",
      "Loss:  1.0988675\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  738\n",
      "Loss:  1.0996068\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  739\n",
      "Loss:  1.099074\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  740\n",
      "Loss:  1.0990897\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  741\n",
      "Loss:  1.0995501\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  742\n",
      "Loss:  1.0989182\n",
      "Accuracy:  0.32666666666666666\n",
      "Iteration:  743\n",
      "Loss:  1.0994928\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  744\n",
      "Loss:  1.1000364\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  745\n",
      "Loss:  1.0999624\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  746\n",
      "Loss:  1.1012262\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  747\n",
      "Loss:  1.099494\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  748\n",
      "Loss:  1.0994145\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  749\n",
      "Loss:  1.1012635\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  750\n",
      "Loss:  1.0981468\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  751\n",
      "Loss:  1.1002294\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  752\n",
      "Loss:  1.0995322\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  753\n",
      "Loss:  1.0995473\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  754\n",
      "Loss:  1.0990924\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  755\n",
      "Loss:  1.0988048\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  756\n",
      "Loss:  1.0987468\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  757\n",
      "Loss:  1.1011733\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  758\n",
      "Loss:  1.0991035\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  759\n",
      "Loss:  1.0997868\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  760\n",
      "Loss:  1.0987865\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  761\n",
      "Loss:  1.0987526\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  762\n",
      "Loss:  1.0996699\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  763\n",
      "Loss:  1.0992038\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  764\n",
      "Loss:  1.0997186\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  765\n",
      "Loss:  1.0998402\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  766\n",
      "Loss:  1.0987817\n",
      "Accuracy:  0.5166666666666667\n",
      "Iteration:  767\n",
      "Loss:  1.0995873\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  768\n",
      "Loss:  1.101415\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  769\n",
      "Loss:  1.0985832\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  770\n",
      "Loss:  1.099211\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  771\n",
      "Loss:  1.1019963\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  772\n",
      "Loss:  1.0984546\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  773\n",
      "Loss:  1.1002808\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  774\n",
      "Loss:  1.0999078\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  775\n",
      "Loss:  1.0993531\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  776\n",
      "Loss:  1.1008726\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  777\n",
      "Loss:  1.0993396\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  778\n",
      "Loss:  1.0998242\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  779\n",
      "Loss:  1.0989875\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  780\n",
      "Loss:  1.0984662\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  781\n",
      "Loss:  1.0996224\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  782\n",
      "Loss:  1.0983219\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  783\n",
      "Loss:  1.0995193\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  784\n",
      "Loss:  1.0982732\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  785\n",
      "Loss:  1.0994114\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  786\n",
      "Loss:  1.0989679\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  787\n",
      "Loss:  1.1016927\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  788\n",
      "Loss:  1.0995812\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  789\n",
      "Loss:  1.0983609\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  790\n",
      "Loss:  1.0988139\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  791\n",
      "Loss:  1.0988204\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  792\n",
      "Loss:  1.0990063\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  793\n",
      "Loss:  1.0991082\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  794\n",
      "Loss:  1.0993668\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  795\n",
      "Loss:  1.09941\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  796\n",
      "Loss:  1.1011232\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  797\n",
      "Loss:  1.0996388\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  798\n",
      "Loss:  1.100132\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  799\n",
      "Loss:  1.1000222\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  800\n",
      "Loss:  1.0984086\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  801\n",
      "Loss:  1.0989487\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  802\n",
      "Loss:  1.1005737\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  803\n",
      "Loss:  1.1020653\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  804\n",
      "Loss:  1.0979494\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  805\n",
      "Loss:  1.099741\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  806\n",
      "Loss:  1.0993028\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  807\n",
      "Loss:  1.0986501\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  808\n",
      "Loss:  1.0985062\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  809\n",
      "Loss:  1.0988559\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  810\n",
      "Loss:  1.099883\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  811\n",
      "Loss:  1.1000116\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  812\n",
      "Loss:  1.0989826\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  813\n",
      "Loss:  1.0993131\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  814\n",
      "Loss:  1.0992041\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  815\n",
      "Loss:  1.0998561\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  816\n",
      "Loss:  1.0987614\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  817\n",
      "Loss:  1.1001947\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  818\n",
      "Loss:  1.0990785\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  819\n",
      "Loss:  1.098844\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  820\n",
      "Loss:  1.0989865\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  821\n",
      "Loss:  1.0992684\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  822\n",
      "Loss:  1.0998424\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  823\n",
      "Loss:  1.0983925\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  824\n",
      "Loss:  1.0990971\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  825\n",
      "Loss:  1.0995495\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  826\n",
      "Loss:  1.098825\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  827\n",
      "Loss:  1.0985659\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  828\n",
      "Loss:  1.0996735\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  829\n",
      "Loss:  1.1005503\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  830\n",
      "Loss:  1.0987064\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  831\n",
      "Loss:  1.1001599\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  832\n",
      "Loss:  1.0992643\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  833\n",
      "Loss:  1.0979873\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  834\n",
      "Loss:  1.0992057\n",
      "Accuracy:  0.3433333333333333\n",
      "Iteration:  835\n",
      "Loss:  1.1011649\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  836\n",
      "Loss:  1.0991963\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  837\n",
      "Loss:  1.099263\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  838\n",
      "Loss:  1.099109\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  839\n",
      "Loss:  1.099337\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  840\n",
      "Loss:  1.098514\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  841\n",
      "Loss:  1.0991199\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  842\n",
      "Loss:  1.0986469\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  843\n",
      "Loss:  1.0989945\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  844\n",
      "Loss:  1.1001745\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  845\n",
      "Loss:  1.1003158\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  846\n",
      "Loss:  1.09984\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  847\n",
      "Loss:  1.100089\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  848\n",
      "Loss:  1.0999695\n",
      "Accuracy:  0.26\n",
      "Iteration:  849\n",
      "Loss:  1.0995389\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  850\n",
      "Loss:  1.099133\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  851\n",
      "Loss:  1.09876\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  852\n",
      "Loss:  1.0996883\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  853\n",
      "Loss:  1.0985813\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  854\n",
      "Loss:  1.0993602\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  855\n",
      "Loss:  1.1000654\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  856\n",
      "Loss:  1.0989547\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  857\n",
      "Loss:  1.1001463\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  858\n",
      "Loss:  1.1004924\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  859\n",
      "Loss:  1.0990485\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  860\n",
      "Loss:  1.0988741\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  861\n",
      "Loss:  1.0992774\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  862\n",
      "Loss:  1.0989496\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  863\n",
      "Loss:  1.0987396\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  864\n",
      "Loss:  1.0986481\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  865\n",
      "Loss:  1.100116\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  866\n",
      "Loss:  1.0993813\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  867\n",
      "Loss:  1.0987788\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  868\n",
      "Loss:  1.1005473\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  869\n",
      "Loss:  1.099136\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  870\n",
      "Loss:  1.1009656\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  871\n",
      "Loss:  1.0989559\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  872\n",
      "Loss:  1.0990201\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  873\n",
      "Loss:  1.0983067\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  874\n",
      "Loss:  1.0972673\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  875\n",
      "Loss:  1.0989101\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  876\n",
      "Loss:  1.0990603\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  877\n",
      "Loss:  1.0991381\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  878\n",
      "Loss:  1.0998688\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  879\n",
      "Loss:  1.1001219\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  880\n",
      "Loss:  1.0986248\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  881\n",
      "Loss:  1.0993948\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  882\n",
      "Loss:  1.0984454\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  883\n",
      "Loss:  1.0995983\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  884\n",
      "Loss:  1.1001403\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  885\n",
      "Loss:  1.0986588\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  886\n",
      "Loss:  1.1003298\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  887\n",
      "Loss:  1.0999676\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  888\n",
      "Loss:  1.0994759\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  889\n",
      "Loss:  1.098451\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  890\n",
      "Loss:  1.0990022\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  891\n",
      "Loss:  1.0995291\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  892\n",
      "Loss:  1.0985776\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  893\n",
      "Loss:  1.098631\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  894\n",
      "Loss:  1.096895\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  895\n",
      "Loss:  1.0992144\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  896\n",
      "Loss:  1.0986576\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  897\n",
      "Loss:  1.0990973\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  898\n",
      "Loss:  1.0969734\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  899\n",
      "Loss:  1.0988541\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  900\n",
      "Loss:  1.1017934\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  901\n",
      "Loss:  1.0994601\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  902\n",
      "Loss:  1.0995295\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  903\n",
      "Loss:  1.0986722\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  904\n",
      "Loss:  1.1004136\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  905\n",
      "Loss:  1.101135\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  906\n",
      "Loss:  1.0985936\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  907\n",
      "Loss:  1.0989312\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  908\n",
      "Loss:  1.0993178\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  909\n",
      "Loss:  1.0989418\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  910\n",
      "Loss:  1.0988079\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  911\n",
      "Loss:  1.09941\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  912\n",
      "Loss:  1.10157\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  913\n",
      "Loss:  1.0988466\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  914\n",
      "Loss:  1.0977244\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  915\n",
      "Loss:  1.0988363\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  916\n",
      "Loss:  1.1006118\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  917\n",
      "Loss:  1.1005017\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  918\n",
      "Loss:  1.0986011\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  919\n",
      "Loss:  1.097889\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  920\n",
      "Loss:  1.0982689\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  921\n",
      "Loss:  1.1025828\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  922\n",
      "Loss:  1.0994084\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  923\n",
      "Loss:  1.1023281\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  924\n",
      "Loss:  1.1001707\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  925\n",
      "Loss:  1.1003178\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  926\n",
      "Loss:  1.0998448\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  927\n",
      "Loss:  1.1002815\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  928\n",
      "Loss:  1.0986365\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  929\n",
      "Loss:  1.0992714\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  930\n",
      "Loss:  1.0993538\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  931\n",
      "Loss:  1.099515\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  932\n",
      "Loss:  1.1000291\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  933\n",
      "Loss:  1.0986185\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  934\n",
      "Loss:  1.0995265\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  935\n",
      "Loss:  1.0992657\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  936\n",
      "Loss:  1.0988643\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  937\n",
      "Loss:  1.0996021\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  938\n",
      "Loss:  1.0982648\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  939\n",
      "Loss:  1.1004598\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  940\n",
      "Loss:  1.0986682\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  941\n",
      "Loss:  1.0991876\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  942\n",
      "Loss:  1.1000599\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  943\n",
      "Loss:  1.0990942\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  944\n",
      "Loss:  1.099023\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  945\n",
      "Loss:  1.1001575\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  946\n",
      "Loss:  1.0982224\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  947\n",
      "Loss:  1.1012625\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  948\n",
      "Loss:  1.0988278\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  949\n",
      "Loss:  1.0987475\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  950\n",
      "Loss:  1.0998985\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  951\n",
      "Loss:  1.0987025\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  952\n",
      "Loss:  1.0995822\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  953\n",
      "Loss:  1.098898\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  954\n",
      "Loss:  1.099948\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  955\n",
      "Loss:  1.0990888\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  956\n",
      "Loss:  1.0998377\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  957\n",
      "Loss:  1.0988718\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  958\n",
      "Loss:  1.0989765\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  959\n",
      "Loss:  1.098783\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  960\n",
      "Loss:  1.0986936\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  961\n",
      "Loss:  1.0984833\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  962\n",
      "Loss:  1.0980319\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  963\n",
      "Loss:  1.0997093\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  964\n",
      "Loss:  1.0988828\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  965\n",
      "Loss:  1.0999764\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  966\n",
      "Loss:  1.0997864\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  967\n",
      "Loss:  1.100732\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  968\n",
      "Loss:  1.0988967\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  969\n",
      "Loss:  1.1000472\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  970\n",
      "Loss:  1.0988495\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  971\n",
      "Loss:  1.0991687\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  972\n",
      "Loss:  1.0979105\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  973\n",
      "Loss:  1.0987976\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  974\n",
      "Loss:  1.0990468\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  975\n",
      "Loss:  1.1003412\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  976\n",
      "Loss:  1.0987439\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  977\n",
      "Loss:  1.0999932\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  978\n",
      "Loss:  1.0995243\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  979\n",
      "Loss:  1.099887\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  980\n",
      "Loss:  1.0991132\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  981\n",
      "Loss:  1.0992247\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  982\n",
      "Loss:  1.0995729\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  983\n",
      "Loss:  1.1002946\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  984\n",
      "Loss:  1.1004748\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  985\n",
      "Loss:  1.1007924\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  986\n",
      "Loss:  1.09785\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  987\n",
      "Loss:  1.0993707\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  988\n",
      "Loss:  1.0996617\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  989\n",
      "Loss:  1.0997734\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  990\n",
      "Loss:  1.1006744\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  991\n",
      "Loss:  1.0993695\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  992\n",
      "Loss:  1.0992432\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  993\n",
      "Loss:  1.0990256\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  994\n",
      "Loss:  1.0987535\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  995\n",
      "Loss:  1.0995901\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  996\n",
      "Loss:  1.1009682\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  997\n",
      "Loss:  1.0997179\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  998\n",
      "Loss:  1.1000987\n",
      "Accuracy:  0.3333333333333333\n",
      "Iteration:  999\n",
      "Loss:  1.0990722\n",
      "Accuracy:  0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# In the below given approach we try randomly set weights and biases\n",
    "# and calculate the loss and accuracy.\n",
    "# If the loss decreases if simply set the new weights as the current weights.\n",
    "\n",
    "X, y = vertical_data(samples=100, classes=3)\n",
    "\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "activation1 = Activation_ReLU()\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "loss_function = Loss_Categorical_Cross_Entropy()\n",
    "\n",
    "lowest_loss = 9999999\n",
    "best_dense1_weights = dense1.weights.copy()\n",
    "best_dense1_biases = dense1.biases.copy()\n",
    "best_dense2_weights = dense2.weights.copy()\n",
    "best_dense2_biases = dense2.biases.copy()\n",
    "\n",
    "for iteration in range(1000):\n",
    "\n",
    "    dense1.weights = 0.05 * np.random.randn(2, 3)\n",
    "    dense1.biases = 0.05 * np.random.randn(1, 3)\n",
    "    dense2.weights = 0.05 * np.random.randn(3, 3)\n",
    "    dense2.biases = 0.05 * np.random.randn(1, 3)\n",
    "\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    activation2.forward(dense2.output)\n",
    "\n",
    "    loss = loss_function.calculate(activation2.output, y)\n",
    "\n",
    "    predictions = np.argmax(activation2.output, axis=1)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "\n",
    "    if(loss < lowest_loss):\n",
    "\n",
    "        print(\"Iteration: \", iteration)\n",
    "        print(\"Loss: \", loss)\n",
    "        print(\"Accuracy: \", accuracy)\n",
    "\n",
    "        loss = lowest_loss\n",
    "        best_dense1_weights = dense1.weights.copy()\n",
    "        best_dense1_biases = dense1.biases.copy()\n",
    "        best_dense2_weights = dense2.weights.copy()\n",
    "        best_dense2_biases = dense2.biases.copy()\n",
    "\n",
    "# The output of the above code is not desirable, \n",
    "# we can see that the accuracy is barely increase and the loss is also slightly decreased.\n",
    "# We will try another approach below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Loss:  1.0989758\n",
      "Accuracy: 0.3333333333333333\n",
      "\n",
      "Iteration:  3\n",
      "Loss:  1.098763\n",
      "Accuracy: 0.3333333333333333\n",
      "\n",
      "Iteration:  6\n",
      "Loss:  1.0970205\n",
      "Accuracy: 0.3333333333333333\n",
      "\n",
      "Iteration:  9\n",
      "Loss:  1.0968492\n",
      "Accuracy: 0.63\n",
      "\n",
      "Iteration:  10\n",
      "Loss:  1.09537\n",
      "Accuracy: 0.3333333333333333\n",
      "\n",
      "Iteration:  18\n",
      "Loss:  1.0905586\n",
      "Accuracy: 0.3933333333333333\n",
      "\n",
      "Iteration:  21\n",
      "Loss:  1.0845269\n",
      "Accuracy: 0.3333333333333333\n",
      "\n",
      "Iteration:  26\n",
      "Loss:  1.0814284\n",
      "Accuracy: 0.3333333333333333\n",
      "\n",
      "Iteration:  28\n",
      "Loss:  1.0808738\n",
      "Accuracy: 0.3333333333333333\n",
      "\n",
      "Iteration:  40\n",
      "Loss:  1.080295\n",
      "Accuracy: 0.3333333333333333\n",
      "\n",
      "Iteration:  42\n",
      "Loss:  1.0772412\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  62\n",
      "Loss:  1.0767745\n",
      "Accuracy: 0.5333333333333333\n",
      "\n",
      "Iteration:  65\n",
      "Loss:  1.072059\n",
      "Accuracy: 0.4666666666666667\n",
      "\n",
      "Iteration:  66\n",
      "Loss:  1.0715542\n",
      "Accuracy: 0.53\n",
      "\n",
      "Iteration:  67\n",
      "Loss:  1.0705723\n",
      "Accuracy: 0.63\n",
      "\n",
      "Iteration:  69\n",
      "Loss:  1.0623716\n",
      "Accuracy: 0.5866666666666667\n",
      "\n",
      "Iteration:  70\n",
      "Loss:  1.0597392\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  71\n",
      "Loss:  1.0466945\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  73\n",
      "Loss:  1.0457199\n",
      "Accuracy: 0.5433333333333333\n",
      "\n",
      "Iteration:  74\n",
      "Loss:  1.0421349\n",
      "Accuracy: 0.34\n",
      "\n",
      "Iteration:  75\n",
      "Loss:  1.03098\n",
      "Accuracy: 0.5466666666666666\n",
      "\n",
      "Iteration:  77\n",
      "Loss:  1.0154423\n",
      "Accuracy: 0.6633333333333333\n",
      "\n",
      "Iteration:  78\n",
      "Loss:  1.003403\n",
      "Accuracy: 0.5633333333333334\n",
      "\n",
      "Iteration:  82\n",
      "Loss:  0.99430126\n",
      "Accuracy: 0.5\n",
      "\n",
      "Iteration:  86\n",
      "Loss:  0.9885789\n",
      "Accuracy: 0.52\n",
      "\n",
      "Iteration:  87\n",
      "Loss:  0.98525023\n",
      "Accuracy: 0.49666666666666665\n",
      "\n",
      "Iteration:  88\n",
      "Loss:  0.98289156\n",
      "Accuracy: 0.43666666666666665\n",
      "\n",
      "Iteration:  89\n",
      "Loss:  0.97519183\n",
      "Accuracy: 0.5033333333333333\n",
      "\n",
      "Iteration:  92\n",
      "Loss:  0.97345054\n",
      "Accuracy: 0.4266666666666667\n",
      "\n",
      "Iteration:  93\n",
      "Loss:  0.9709287\n",
      "Accuracy: 0.5033333333333333\n",
      "\n",
      "Iteration:  94\n",
      "Loss:  0.9698231\n",
      "Accuracy: 0.6233333333333333\n",
      "\n",
      "Iteration:  95\n",
      "Loss:  0.9589232\n",
      "Accuracy: 0.6333333333333333\n",
      "\n",
      "Iteration:  97\n",
      "Loss:  0.95366025\n",
      "Accuracy: 0.56\n",
      "\n",
      "Iteration:  98\n",
      "Loss:  0.9461609\n",
      "Accuracy: 0.44666666666666666\n",
      "\n",
      "Iteration:  99\n",
      "Loss:  0.9292625\n",
      "Accuracy: 0.5433333333333333\n",
      "\n",
      "Iteration:  100\n",
      "Loss:  0.92318076\n",
      "Accuracy: 0.5833333333333334\n",
      "\n",
      "Iteration:  103\n",
      "Loss:  0.9104832\n",
      "Accuracy: 0.6933333333333334\n",
      "\n",
      "Iteration:  104\n",
      "Loss:  0.90514994\n",
      "Accuracy: 0.6333333333333333\n",
      "\n",
      "Iteration:  105\n",
      "Loss:  0.8997421\n",
      "Accuracy: 0.66\n",
      "\n",
      "Iteration:  106\n",
      "Loss:  0.8952559\n",
      "Accuracy: 0.62\n",
      "\n",
      "Iteration:  110\n",
      "Loss:  0.8836614\n",
      "Accuracy: 0.6933333333333334\n",
      "\n",
      "Iteration:  117\n",
      "Loss:  0.8826926\n",
      "Accuracy: 0.6466666666666666\n",
      "\n",
      "Iteration:  121\n",
      "Loss:  0.8767414\n",
      "Accuracy: 0.6366666666666667\n",
      "\n",
      "Iteration:  122\n",
      "Loss:  0.86521524\n",
      "Accuracy: 0.66\n",
      "\n",
      "Iteration:  125\n",
      "Loss:  0.85700095\n",
      "Accuracy: 0.6566666666666666\n",
      "\n",
      "Iteration:  130\n",
      "Loss:  0.85217714\n",
      "Accuracy: 0.6433333333333333\n",
      "\n",
      "Iteration:  135\n",
      "Loss:  0.8437198\n",
      "Accuracy: 0.6966666666666667\n",
      "\n",
      "Iteration:  139\n",
      "Loss:  0.84182376\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  140\n",
      "Loss:  0.84078056\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  143\n",
      "Loss:  0.8379782\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  144\n",
      "Loss:  0.8368814\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  145\n",
      "Loss:  0.8325418\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  146\n",
      "Loss:  0.83062774\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  148\n",
      "Loss:  0.82534873\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  151\n",
      "Loss:  0.8239946\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  152\n",
      "Loss:  0.82296395\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  153\n",
      "Loss:  0.818862\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  154\n",
      "Loss:  0.8133004\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  157\n",
      "Loss:  0.8131072\n",
      "Accuracy: 0.6933333333333334\n",
      "\n",
      "Iteration:  158\n",
      "Loss:  0.8106171\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  160\n",
      "Loss:  0.8070146\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  163\n",
      "Loss:  0.79946005\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  167\n",
      "Loss:  0.79669404\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  170\n",
      "Loss:  0.78647363\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  181\n",
      "Loss:  0.78054416\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  184\n",
      "Loss:  0.77441597\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  185\n",
      "Loss:  0.7689836\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  189\n",
      "Loss:  0.7654246\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  190\n",
      "Loss:  0.76353496\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  191\n",
      "Loss:  0.75333214\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  194\n",
      "Loss:  0.75139457\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  197\n",
      "Loss:  0.73682386\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  198\n",
      "Loss:  0.7338765\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  199\n",
      "Loss:  0.72514313\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  201\n",
      "Loss:  0.71923286\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  204\n",
      "Loss:  0.71233\n",
      "Accuracy: 0.7\n",
      "\n",
      "Iteration:  205\n",
      "Loss:  0.7093634\n",
      "Accuracy: 0.7033333333333334\n",
      "\n",
      "Iteration:  207\n",
      "Loss:  0.709346\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Iteration:  208\n",
      "Loss:  0.70857245\n",
      "Accuracy: 0.6933333333333334\n",
      "\n",
      "Iteration:  209\n",
      "Loss:  0.70775515\n",
      "Accuracy: 0.7133333333333334\n",
      "\n",
      "Iteration:  210\n",
      "Loss:  0.7003384\n",
      "Accuracy: 0.7233333333333334\n",
      "\n",
      "Iteration:  211\n",
      "Loss:  0.69798845\n",
      "Accuracy: 0.7366666666666667\n",
      "\n",
      "Iteration:  217\n",
      "Loss:  0.6804076\n",
      "Accuracy: 0.76\n",
      "\n",
      "Iteration:  218\n",
      "Loss:  0.67732745\n",
      "Accuracy: 0.73\n",
      "\n",
      "Iteration:  219\n",
      "Loss:  0.6734736\n",
      "Accuracy: 0.6833333333333333\n",
      "\n",
      "Iteration:  223\n",
      "Loss:  0.6676483\n",
      "Accuracy: 0.7533333333333333\n",
      "\n",
      "Iteration:  228\n",
      "Loss:  0.65768087\n",
      "Accuracy: 0.7533333333333333\n",
      "\n",
      "Iteration:  229\n",
      "Loss:  0.64853406\n",
      "Accuracy: 0.7466666666666667\n",
      "\n",
      "Iteration:  230\n",
      "Loss:  0.6373236\n",
      "Accuracy: 0.7633333333333333\n",
      "\n",
      "Iteration:  231\n",
      "Loss:  0.6247831\n",
      "Accuracy: 0.7866666666666666\n",
      "\n",
      "Iteration:  232\n",
      "Loss:  0.6158636\n",
      "Accuracy: 0.8133333333333334\n",
      "\n",
      "Iteration:  234\n",
      "Loss:  0.60984844\n",
      "Accuracy: 0.8133333333333334\n",
      "\n",
      "Iteration:  235\n",
      "Loss:  0.60495526\n",
      "Accuracy: 0.83\n",
      "\n",
      "Iteration:  238\n",
      "Loss:  0.60468936\n",
      "Accuracy: 0.8266666666666667\n",
      "\n",
      "Iteration:  246\n",
      "Loss:  0.5922004\n",
      "Accuracy: 0.88\n",
      "\n",
      "Iteration:  249\n",
      "Loss:  0.5904222\n",
      "Accuracy: 0.8866666666666667\n",
      "\n",
      "Iteration:  250\n",
      "Loss:  0.5885703\n",
      "Accuracy: 0.8833333333333333\n",
      "\n",
      "Iteration:  251\n",
      "Loss:  0.58810884\n",
      "Accuracy: 0.89\n",
      "\n",
      "Iteration:  252\n",
      "Loss:  0.58538806\n",
      "Accuracy: 0.9\n",
      "\n",
      "Iteration:  253\n",
      "Loss:  0.58410645\n",
      "Accuracy: 0.8966666666666666\n",
      "\n",
      "Iteration:  255\n",
      "Loss:  0.58314884\n",
      "Accuracy: 0.9033333333333333\n",
      "\n",
      "Iteration:  256\n",
      "Loss:  0.58192515\n",
      "Accuracy: 0.9\n",
      "\n",
      "Iteration:  259\n",
      "Loss:  0.5680941\n",
      "Accuracy: 0.8966666666666666\n",
      "\n",
      "Iteration:  260\n",
      "Loss:  0.56187224\n",
      "Accuracy: 0.9\n",
      "\n",
      "Iteration:  262\n",
      "Loss:  0.5618047\n",
      "Accuracy: 0.8866666666666667\n",
      "\n",
      "Iteration:  267\n",
      "Loss:  0.5556269\n",
      "Accuracy: 0.8733333333333333\n",
      "\n",
      "Iteration:  268\n",
      "Loss:  0.55098075\n",
      "Accuracy: 0.8533333333333334\n",
      "\n",
      "Iteration:  277\n",
      "Loss:  0.5446096\n",
      "Accuracy: 0.8866666666666667\n",
      "\n",
      "Iteration:  280\n",
      "Loss:  0.5440891\n",
      "Accuracy: 0.8933333333333333\n",
      "\n",
      "Iteration:  281\n",
      "Loss:  0.54119086\n",
      "Accuracy: 0.8933333333333333\n",
      "\n",
      "Iteration:  286\n",
      "Loss:  0.5398884\n",
      "Accuracy: 0.9133333333333333\n",
      "\n",
      "Iteration:  290\n",
      "Loss:  0.5382666\n",
      "Accuracy: 0.88\n",
      "\n",
      "Iteration:  304\n",
      "Loss:  0.5340113\n",
      "Accuracy: 0.9133333333333333\n",
      "\n",
      "Iteration:  308\n",
      "Loss:  0.53272134\n",
      "Accuracy: 0.8866666666666667\n",
      "\n",
      "Iteration:  310\n",
      "Loss:  0.53060615\n",
      "Accuracy: 0.8966666666666666\n",
      "\n",
      "Iteration:  311\n",
      "Loss:  0.52608305\n",
      "Accuracy: 0.8966666666666666\n",
      "\n",
      "Iteration:  314\n",
      "Loss:  0.52480817\n",
      "Accuracy: 0.9\n",
      "\n",
      "Iteration:  317\n",
      "Loss:  0.52414197\n",
      "Accuracy: 0.91\n",
      "\n",
      "Iteration:  318\n",
      "Loss:  0.523662\n",
      "Accuracy: 0.9\n",
      "\n",
      "Iteration:  323\n",
      "Loss:  0.5207695\n",
      "Accuracy: 0.8966666666666666\n",
      "\n",
      "Iteration:  329\n",
      "Loss:  0.51151097\n",
      "Accuracy: 0.9\n",
      "\n",
      "Iteration:  339\n",
      "Loss:  0.50707304\n",
      "Accuracy: 0.89\n",
      "\n",
      "Iteration:  342\n",
      "Loss:  0.50271106\n",
      "Accuracy: 0.91\n",
      "\n",
      "Iteration:  344\n",
      "Loss:  0.49227697\n",
      "Accuracy: 0.92\n",
      "\n",
      "Iteration:  346\n",
      "Loss:  0.48926675\n",
      "Accuracy: 0.91\n",
      "\n",
      "Iteration:  352\n",
      "Loss:  0.488172\n",
      "Accuracy: 0.9\n",
      "\n",
      "Iteration:  356\n",
      "Loss:  0.48788238\n",
      "Accuracy: 0.8866666666666667\n",
      "\n",
      "Iteration:  359\n",
      "Loss:  0.48125955\n",
      "Accuracy: 0.89\n",
      "\n",
      "Iteration:  360\n",
      "Loss:  0.47958058\n",
      "Accuracy: 0.8866666666666667\n",
      "\n",
      "Iteration:  361\n",
      "Loss:  0.47417334\n",
      "Accuracy: 0.9\n",
      "\n",
      "Iteration:  364\n",
      "Loss:  0.4717451\n",
      "Accuracy: 0.89\n",
      "\n",
      "Iteration:  366\n",
      "Loss:  0.47142646\n",
      "Accuracy: 0.88\n",
      "\n",
      "Iteration:  371\n",
      "Loss:  0.46362922\n",
      "Accuracy: 0.89\n",
      "\n",
      "Iteration:  376\n",
      "Loss:  0.45528212\n",
      "Accuracy: 0.9033333333333333\n",
      "\n",
      "Iteration:  377\n",
      "Loss:  0.4551356\n",
      "Accuracy: 0.9\n",
      "\n",
      "Iteration:  385\n",
      "Loss:  0.44959533\n",
      "Accuracy: 0.9066666666666666\n",
      "\n",
      "Iteration:  386\n",
      "Loss:  0.44694728\n",
      "Accuracy: 0.8933333333333333\n",
      "\n",
      "Iteration:  390\n",
      "Loss:  0.44055736\n",
      "Accuracy: 0.9166666666666666\n",
      "\n",
      "Iteration:  394\n",
      "Loss:  0.4361347\n",
      "Accuracy: 0.9166666666666666\n",
      "\n",
      "Iteration:  396\n",
      "Loss:  0.43246013\n",
      "Accuracy: 0.9033333333333333\n",
      "\n",
      "Iteration:  398\n",
      "Loss:  0.42832032\n",
      "Accuracy: 0.9166666666666666\n",
      "\n",
      "Iteration:  400\n",
      "Loss:  0.4239827\n",
      "Accuracy: 0.8933333333333333\n",
      "\n",
      "Iteration:  406\n",
      "Loss:  0.42388892\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  417\n",
      "Loss:  0.42315552\n",
      "Accuracy: 0.9066666666666666\n",
      "\n",
      "Iteration:  421\n",
      "Loss:  0.41917628\n",
      "Accuracy: 0.8966666666666666\n",
      "\n",
      "Iteration:  423\n",
      "Loss:  0.41644132\n",
      "Accuracy: 0.9\n",
      "\n",
      "Iteration:  428\n",
      "Loss:  0.41140616\n",
      "Accuracy: 0.9033333333333333\n",
      "\n",
      "Iteration:  432\n",
      "Loss:  0.40890777\n",
      "Accuracy: 0.9166666666666666\n",
      "\n",
      "Iteration:  434\n",
      "Loss:  0.4051037\n",
      "Accuracy: 0.9033333333333333\n",
      "\n",
      "Iteration:  441\n",
      "Loss:  0.4046271\n",
      "Accuracy: 0.9166666666666666\n",
      "\n",
      "Iteration:  458\n",
      "Loss:  0.40359202\n",
      "Accuracy: 0.91\n",
      "\n",
      "Iteration:  460\n",
      "Loss:  0.40278026\n",
      "Accuracy: 0.92\n",
      "\n",
      "Iteration:  464\n",
      "Loss:  0.3988149\n",
      "Accuracy: 0.92\n",
      "\n",
      "Iteration:  466\n",
      "Loss:  0.39457873\n",
      "Accuracy: 0.9\n",
      "\n",
      "Iteration:  471\n",
      "Loss:  0.39407843\n",
      "Accuracy: 0.9\n",
      "\n",
      "Iteration:  472\n",
      "Loss:  0.3879429\n",
      "Accuracy: 0.9133333333333333\n",
      "\n",
      "Iteration:  477\n",
      "Loss:  0.38714343\n",
      "Accuracy: 0.91\n",
      "\n",
      "Iteration:  480\n",
      "Loss:  0.3851299\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  482\n",
      "Loss:  0.38368577\n",
      "Accuracy: 0.9\n",
      "\n",
      "Iteration:  491\n",
      "Loss:  0.38320008\n",
      "Accuracy: 0.9066666666666666\n",
      "\n",
      "Iteration:  492\n",
      "Loss:  0.38205725\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  494\n",
      "Loss:  0.3806115\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  496\n",
      "Loss:  0.3790359\n",
      "Accuracy: 0.92\n",
      "\n",
      "Iteration:  505\n",
      "Loss:  0.37881336\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  506\n",
      "Loss:  0.37712583\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  510\n",
      "Loss:  0.37021062\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  511\n",
      "Loss:  0.36851546\n",
      "Accuracy: 0.9166666666666666\n",
      "\n",
      "Iteration:  512\n",
      "Loss:  0.36511448\n",
      "Accuracy: 0.9166666666666666\n",
      "\n",
      "Iteration:  513\n",
      "Loss:  0.3614815\n",
      "Accuracy: 0.9133333333333333\n",
      "\n",
      "Iteration:  514\n",
      "Loss:  0.36026332\n",
      "Accuracy: 0.9133333333333333\n",
      "\n",
      "Iteration:  516\n",
      "Loss:  0.36011246\n",
      "Accuracy: 0.9033333333333333\n",
      "\n",
      "Iteration:  517\n",
      "Loss:  0.35964143\n",
      "Accuracy: 0.91\n",
      "\n",
      "Iteration:  520\n",
      "Loss:  0.35468662\n",
      "Accuracy: 0.9066666666666666\n",
      "\n",
      "Iteration:  521\n",
      "Loss:  0.35466534\n",
      "Accuracy: 0.91\n",
      "\n",
      "Iteration:  524\n",
      "Loss:  0.35076857\n",
      "Accuracy: 0.9066666666666666\n",
      "\n",
      "Iteration:  527\n",
      "Loss:  0.3478132\n",
      "Accuracy: 0.9166666666666666\n",
      "\n",
      "Iteration:  535\n",
      "Loss:  0.34544748\n",
      "Accuracy: 0.9066666666666666\n",
      "\n",
      "Iteration:  540\n",
      "Loss:  0.3405075\n",
      "Accuracy: 0.91\n",
      "\n",
      "Iteration:  542\n",
      "Loss:  0.3397076\n",
      "Accuracy: 0.9133333333333333\n",
      "\n",
      "Iteration:  543\n",
      "Loss:  0.33736497\n",
      "Accuracy: 0.9133333333333333\n",
      "\n",
      "Iteration:  544\n",
      "Loss:  0.33578327\n",
      "Accuracy: 0.91\n",
      "\n",
      "Iteration:  545\n",
      "Loss:  0.33456048\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  548\n",
      "Loss:  0.32965982\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  549\n",
      "Loss:  0.3274325\n",
      "Accuracy: 0.92\n",
      "\n",
      "Iteration:  558\n",
      "Loss:  0.32653758\n",
      "Accuracy: 0.92\n",
      "\n",
      "Iteration:  574\n",
      "Loss:  0.3195191\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  589\n",
      "Loss:  0.31815574\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  594\n",
      "Loss:  0.3116345\n",
      "Accuracy: 0.92\n",
      "\n",
      "Iteration:  600\n",
      "Loss:  0.31033418\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  601\n",
      "Loss:  0.30859375\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  602\n",
      "Loss:  0.30826598\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  604\n",
      "Loss:  0.3056516\n",
      "Accuracy: 0.9133333333333333\n",
      "\n",
      "Iteration:  610\n",
      "Loss:  0.30473214\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  615\n",
      "Loss:  0.3038625\n",
      "Accuracy: 0.92\n",
      "\n",
      "Iteration:  616\n",
      "Loss:  0.30161443\n",
      "Accuracy: 0.91\n",
      "\n",
      "Iteration:  620\n",
      "Loss:  0.3006791\n",
      "Accuracy: 0.91\n",
      "\n",
      "Iteration:  623\n",
      "Loss:  0.29573125\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  629\n",
      "Loss:  0.29343334\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  633\n",
      "Loss:  0.29267424\n",
      "Accuracy: 0.92\n",
      "\n",
      "Iteration:  634\n",
      "Loss:  0.2909836\n",
      "Accuracy: 0.9166666666666666\n",
      "\n",
      "Iteration:  637\n",
      "Loss:  0.29021576\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  639\n",
      "Loss:  0.28854823\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  645\n",
      "Loss:  0.28776452\n",
      "Accuracy: 0.9033333333333333\n",
      "\n",
      "Iteration:  646\n",
      "Loss:  0.28132758\n",
      "Accuracy: 0.91\n",
      "\n",
      "Iteration:  652\n",
      "Loss:  0.2736648\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  653\n",
      "Loss:  0.27295288\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  664\n",
      "Loss:  0.27200076\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  671\n",
      "Loss:  0.27146256\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  674\n",
      "Loss:  0.2706239\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  678\n",
      "Loss:  0.26646647\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  680\n",
      "Loss:  0.2649222\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  684\n",
      "Loss:  0.26469743\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  689\n",
      "Loss:  0.2638529\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  690\n",
      "Loss:  0.26205653\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  691\n",
      "Loss:  0.2586203\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  693\n",
      "Loss:  0.25486887\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  697\n",
      "Loss:  0.25119328\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  701\n",
      "Loss:  0.25053716\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  707\n",
      "Loss:  0.25026134\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  709\n",
      "Loss:  0.2479183\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  715\n",
      "Loss:  0.24742278\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  716\n",
      "Loss:  0.24739395\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  730\n",
      "Loss:  0.24709533\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  731\n",
      "Loss:  0.24454898\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  758\n",
      "Loss:  0.24245241\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  762\n",
      "Loss:  0.24155006\n",
      "Accuracy: 0.94\n",
      "\n",
      "Iteration:  763\n",
      "Loss:  0.24148728\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  773\n",
      "Loss:  0.23924546\n",
      "Accuracy: 0.9366666666666666\n",
      "\n",
      "Iteration:  781\n",
      "Loss:  0.23869339\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  793\n",
      "Loss:  0.23776352\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  803\n",
      "Loss:  0.23678955\n",
      "Accuracy: 0.9366666666666666\n",
      "\n",
      "Iteration:  806\n",
      "Loss:  0.23478755\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  809\n",
      "Loss:  0.23473282\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  810\n",
      "Loss:  0.23346868\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  829\n",
      "Loss:  0.23187886\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  835\n",
      "Loss:  0.2311582\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  839\n",
      "Loss:  0.23090896\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  843\n",
      "Loss:  0.22848485\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  855\n",
      "Loss:  0.22640531\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  864\n",
      "Loss:  0.22441894\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  868\n",
      "Loss:  0.22396934\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  872\n",
      "Loss:  0.22266205\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  884\n",
      "Loss:  0.22142807\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  918\n",
      "Loss:  0.22006401\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  921\n",
      "Loss:  0.21982405\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  936\n",
      "Loss:  0.21735306\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  942\n",
      "Loss:  0.2155101\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  952\n",
      "Loss:  0.21383671\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  958\n",
      "Loss:  0.2132875\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  963\n",
      "Loss:  0.21294121\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  974\n",
      "Loss:  0.21252286\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  979\n",
      "Loss:  0.21136057\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  989\n",
      "Loss:  0.2110845\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1029\n",
      "Loss:  0.20975746\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  1041\n",
      "Loss:  0.20906766\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1046\n",
      "Loss:  0.20737363\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  1054\n",
      "Loss:  0.20718963\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1066\n",
      "Loss:  0.20629685\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  1083\n",
      "Loss:  0.20623831\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1085\n",
      "Loss:  0.20559467\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1089\n",
      "Loss:  0.205292\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  1090\n",
      "Loss:  0.20395398\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  1093\n",
      "Loss:  0.20385765\n",
      "Accuracy: 0.92\n",
      "\n",
      "Iteration:  1106\n",
      "Loss:  0.2022451\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1111\n",
      "Loss:  0.20179044\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  1120\n",
      "Loss:  0.20051457\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1122\n",
      "Loss:  0.19899632\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1124\n",
      "Loss:  0.19885968\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  1138\n",
      "Loss:  0.19779572\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1163\n",
      "Loss:  0.19753438\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1164\n",
      "Loss:  0.19572991\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1165\n",
      "Loss:  0.19433238\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1171\n",
      "Loss:  0.19388668\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1180\n",
      "Loss:  0.19169587\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1195\n",
      "Loss:  0.19155496\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  1196\n",
      "Loss:  0.19151108\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1203\n",
      "Loss:  0.19056708\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1218\n",
      "Loss:  0.19023593\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1219\n",
      "Loss:  0.18949977\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1238\n",
      "Loss:  0.18935262\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1239\n",
      "Loss:  0.1889073\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1248\n",
      "Loss:  0.18724355\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  1254\n",
      "Loss:  0.18714257\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  1265\n",
      "Loss:  0.18636118\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1267\n",
      "Loss:  0.18590294\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1276\n",
      "Loss:  0.1849569\n",
      "Accuracy: 0.94\n",
      "\n",
      "Iteration:  1285\n",
      "Loss:  0.1846092\n",
      "Accuracy: 0.9366666666666666\n",
      "\n",
      "Iteration:  1296\n",
      "Loss:  0.1839023\n",
      "Accuracy: 0.9366666666666666\n",
      "\n",
      "Iteration:  1303\n",
      "Loss:  0.18378387\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  1318\n",
      "Loss:  0.18327859\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  1325\n",
      "Loss:  0.18277554\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  1334\n",
      "Loss:  0.18275093\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1335\n",
      "Loss:  0.18189482\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  1341\n",
      "Loss:  0.18188563\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1376\n",
      "Loss:  0.18114877\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  1382\n",
      "Loss:  0.18072064\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1388\n",
      "Loss:  0.180322\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1389\n",
      "Loss:  0.18007845\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  1398\n",
      "Loss:  0.17988195\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  1402\n",
      "Loss:  0.17972769\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  1403\n",
      "Loss:  0.17878367\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1432\n",
      "Loss:  0.1786711\n",
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Iteration:  1450\n",
      "Loss:  0.17855018\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1486\n",
      "Loss:  0.17844334\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1494\n",
      "Loss:  0.17765851\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1499\n",
      "Loss:  0.17736925\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1502\n",
      "Loss:  0.17689182\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1593\n",
      "Loss:  0.1765415\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1597\n",
      "Loss:  0.17648157\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1621\n",
      "Loss:  0.17560178\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1639\n",
      "Loss:  0.17548043\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  1652\n",
      "Loss:  0.1750333\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1674\n",
      "Loss:  0.17481509\n",
      "Accuracy: 0.92\n",
      "\n",
      "Iteration:  1680\n",
      "Loss:  0.17409469\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1734\n",
      "Loss:  0.17379965\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1782\n",
      "Loss:  0.17348693\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1784\n",
      "Loss:  0.17341197\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  1785\n",
      "Loss:  0.17284657\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  1794\n",
      "Loss:  0.17283158\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1797\n",
      "Loss:  0.17248471\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  1809\n",
      "Loss:  0.17240581\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  1814\n",
      "Loss:  0.17232968\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1827\n",
      "Loss:  0.17188008\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  1846\n",
      "Loss:  0.1712076\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  1898\n",
      "Loss:  0.17115991\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  1932\n",
      "Loss:  0.17078677\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  1993\n",
      "Loss:  0.17058314\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  2028\n",
      "Loss:  0.17054935\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  2036\n",
      "Loss:  0.17038943\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  2076\n",
      "Loss:  0.17034198\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  2077\n",
      "Loss:  0.1701205\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  2087\n",
      "Loss:  0.17006244\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  2097\n",
      "Loss:  0.16955303\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  2213\n",
      "Loss:  0.16955282\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  2216\n",
      "Loss:  0.16932335\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  2256\n",
      "Loss:  0.16920762\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  2365\n",
      "Loss:  0.16907153\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  2458\n",
      "Loss:  0.1689962\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  2518\n",
      "Loss:  0.16880977\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  2578\n",
      "Loss:  0.16880031\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  2632\n",
      "Loss:  0.16875443\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  2698\n",
      "Loss:  0.1683506\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  2725\n",
      "Loss:  0.16828386\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  2763\n",
      "Loss:  0.16827115\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  2777\n",
      "Loss:  0.16824679\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  2818\n",
      "Loss:  0.16821453\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  2899\n",
      "Loss:  0.16820195\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  2903\n",
      "Loss:  0.16819832\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  2933\n",
      "Loss:  0.16793013\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  2951\n",
      "Loss:  0.1677512\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  3077\n",
      "Loss:  0.16769402\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  3151\n",
      "Loss:  0.16755824\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  3240\n",
      "Loss:  0.16745949\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  3255\n",
      "Loss:  0.16740176\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  3320\n",
      "Loss:  0.1672442\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  3438\n",
      "Loss:  0.16723603\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  4192\n",
      "Loss:  0.16709979\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  4432\n",
      "Loss:  0.16702439\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  4476\n",
      "Loss:  0.16689211\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  5572\n",
      "Loss:  0.16685697\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  5809\n",
      "Loss:  0.16684929\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  5913\n",
      "Loss:  0.16679619\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  6100\n",
      "Loss:  0.16679582\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  6291\n",
      "Loss:  0.1667406\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  6985\n",
      "Loss:  0.16670677\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  7544\n",
      "Loss:  0.16668646\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  7567\n",
      "Loss:  0.16665085\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  7793\n",
      "Loss:  0.16656922\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  8138\n",
      "Loss:  0.16654994\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  8348\n",
      "Loss:  0.16645995\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  8625\n",
      "Loss:  0.16644907\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  9114\n",
      "Loss:  0.16642836\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  9383\n",
      "Loss:  0.16642629\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  9716\n",
      "Loss:  0.16638619\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  10698\n",
      "Loss:  0.16633402\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  10715\n",
      "Loss:  0.16631334\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  10897\n",
      "Loss:  0.1662691\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  11159\n",
      "Loss:  0.16626322\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  12403\n",
      "Loss:  0.16625743\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  17215\n",
      "Loss:  0.16624247\n",
      "Accuracy: 0.93\n",
      "\n",
      "Iteration:  19414\n",
      "Loss:  0.16621691\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  20644\n",
      "Loss:  0.16621183\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  21103\n",
      "Loss:  0.16620852\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  24125\n",
      "Loss:  0.16617858\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  24658\n",
      "Loss:  0.16614667\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  25477\n",
      "Loss:  0.16614303\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  27717\n",
      "Loss:  0.16613151\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  28552\n",
      "Loss:  0.16612528\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  32070\n",
      "Loss:  0.1661233\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  33262\n",
      "Loss:  0.16612214\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  33274\n",
      "Loss:  0.16611694\n",
      "Accuracy: 0.9233333333333333\n",
      "\n",
      "Iteration:  34624\n",
      "Loss:  0.16610967\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  37999\n",
      "Loss:  0.16608942\n",
      "Accuracy: 0.9266666666666666\n",
      "\n",
      "Iteration:  40620\n",
      "Loss:  0.1660709\n",
      "Accuracy: 0.9233333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X, y = vertical_data(samples=100, classes=3)\n",
    "\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "activation1 = Activation_ReLU()\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "loss_function = Loss_Categorical_Cross_Entropy()\n",
    "\n",
    "lowest_loss = 9999999\n",
    "best_dense1_weights = dense1.weights.copy()\n",
    "best_dense1_biases = dense1.biases.copy()\n",
    "best_dense2_weights = dense2.weights.copy()\n",
    "best_dense2_biases = dense2.biases.copy()\n",
    "\n",
    "for iteration in range(100000):\n",
    "\n",
    "    dense1.weights += 0.05 * np.random.randn(2, 3)\n",
    "    dense1.biases += 0.05 * np.random.randn(1, 3)\n",
    "    dense2.weights += 0.05 * np.random.randn(3, 3)\n",
    "    dense2.biases += 0.05 * np.random.randn(1, 3)\n",
    "\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    activation2.forward(dense2.output)\n",
    "\n",
    "    loss = loss_function.calculate(activation2.output, y)\n",
    "\n",
    "    predictions = np.argmax(activation2.output, axis=1)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "\n",
    "    if loss < lowest_loss:\n",
    "\n",
    "        print(\"Iteration: \", iteration)\n",
    "        print(\"Loss: \", loss)\n",
    "        print(\"Accuracy: {}\\n\".format(accuracy))\n",
    "\n",
    "        best_dense1_weights = dense1.weights.copy()\n",
    "        best_dense1_biases = dense1.biases.copy()\n",
    "        best_dense2_weights = dense2.weights.copy()\n",
    "        best_dense2_biases = dense2.biases.copy()\n",
    "        lowest_loss = loss\n",
    "\n",
    "    else:\n",
    "        dense1.weights = best_dense1_weights.copy()\n",
    "        dense1.biases = best_dense1_biases.copy()\n",
    "        dense2.weights = best_dense2_weights.copy()\n",
    "        dense2.biases = best_dense2_biases.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
